{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3cde6d2-cef8-4c2a-b3b5-b3efaa790353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES = None\n",
      "PyTorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn import metrics\n",
    "import pennylane as qml\n",
    "\n",
    "print(\"CUDA_VISIBLE_DEVICES =\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"PyTorch device:\", device)\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "np.set_printoptions(precision=4, suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e68b83b-52ca-47cf-9059-127a006b29a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satır: 2820 | Özellik sayısı: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>BW</th>\n",
       "      <th>COMED</th>\n",
       "      <th>DOSE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DV</th>\n",
       "      <th>EVID</th>\n",
       "      <th>MDV</th>\n",
       "      <th>AMT</th>\n",
       "      <th>CMT</th>\n",
       "      <th>DVID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.6174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.7783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  BW  COMED  DOSE  TIME       DV  EVID  MDV  AMT  CMT  DVID\n",
       "0   1  58      0     0     0  18.6174     0    0    0    3     2\n",
       "1   1  58      0     0     1  13.7783     0    0    0    3     2\n",
       "2   1  58      0     0     2  16.5747     0    0    0    3     2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "CSV_PATH = \"QIC2025-EstDat.csv\"\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    alt = \"QIC2025-EstDat (1).csv\"\n",
    "    if os.path.exists(alt):\n",
    "        CSV_PATH = alt\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "TARGET   = \"DV\"\n",
    "FEATURES = [\"BW\",\"COMED\",\"DOSE\",\"TIME\",\"EVID\",\"MDV\",\"AMT\",\"CMT\",\"DVID\"]  # 9 özellik\n",
    "df = df.dropna(subset=FEATURES + [TARGET]).copy()\n",
    "\n",
    "print(\"Satır:\", len(df), \"| Özellik sayısı:\", len(FEATURES))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5393e7eb-aa62-40af-9d1a-395b1a16b529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test şekilleri: (2040, 11) (355, 11) (425, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rng = np.random.default_rng(42)\n",
    "uids = df[\"ID\"].unique().copy()\n",
    "rng.shuffle(uids)\n",
    "\n",
    "n_total = len(uids)\n",
    "n_train = int(0.70 * n_total)\n",
    "n_val   = int(0.15 * n_total)\n",
    "\n",
    "train_ids = uids[:n_train]\n",
    "val_ids   = uids[n_train:n_train+n_val]\n",
    "test_ids  = uids[n_train+n_val:]\n",
    "\n",
    "train_df = df[df[\"ID\"].isin(train_ids)].copy()\n",
    "val_df   = df[df[\"ID\"].isin(val_ids)].copy()\n",
    "test_df  = df[df[\"ID\"].isin(test_ids)].copy()\n",
    "\n",
    "\n",
    "print(\"Train/Val/Test şekilleri:\", train_df.shape, val_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f363b2-dd1b-49c0-8db2-1bee4fcb9a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded shapes: (2040, 16) (355, 16) (425, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = train_df[FEATURES].to_numpy(dtype=np.float64)\n",
    "X_val   = val_df[FEATURES].to_numpy(dtype=np.float64)\n",
    "X_test  = test_df[FEATURES].to_numpy(dtype=np.float64)\n",
    "\n",
    "y_train = train_df[TARGET].to_numpy(dtype=np.float64)\n",
    "y_val   = val_df[TARGET].to_numpy(dtype=np.float64)\n",
    "y_test  = test_df[TARGET].to_numpy(dtype=np.float64)\n",
    "\n",
    "mean_ = X_train.mean(axis=0, keepdims=True)\n",
    "std_  = X_train.std(axis=0, keepdims=True)\n",
    "std_[std_ == 0] = 1.0\n",
    "eps = 1e-8\n",
    "\n",
    "def zscore(x):\n",
    "    return (x - mean_) / (std_ + eps)\n",
    "\n",
    "TrainX = zscore(X_train).astype(np.float64)\n",
    "ValX   = zscore(X_val).astype(np.float64)\n",
    "TestX  = zscore(X_test).astype(np.float64)\n",
    "\n",
    "def pad_numpy(x_np, target_len=16):\n",
    "    x_np = np.asarray(x_np, dtype=np.float64)\n",
    "    cur = x_np.shape[1]\n",
    "    if cur >= target_len:\n",
    "        return x_np[:, :target_len]\n",
    "    pad = np.zeros((x_np.shape[0], target_len - cur), dtype=np.float64)\n",
    "    return np.concatenate([x_np, pad], axis=1)\n",
    "\n",
    "TrainX_p = pad_numpy(TrainX, 16)\n",
    "ValX_p   = pad_numpy(ValX, 16)\n",
    "TestX_p  = pad_numpy(TestX, 16)\n",
    "\n",
    "print(\"Padded shapes:\", TrainX_p.shape, ValX_p.shape, TestX_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1958fbb2-0a2d-4909-ac8b-ab8bb982876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hazır: train/val/test loader (CPU → GPU transfer DataLoader içinde yapılacak)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Xtr = torch.from_numpy(TrainX_p)          \n",
    "Ytr = torch.from_numpy(y_train.reshape(-1,1))  \n",
    "\n",
    "Xva = torch.from_numpy(ValX_p)                   \n",
    "Yva = torch.from_numpy(y_val.reshape(-1,1))      \n",
    "\n",
    "Xte = torch.from_numpy(TestX_p)                  \n",
    "Yte = torch.from_numpy(y_test.reshape(-1,1))   \n",
    "\n",
    "pin = (device.type == \"cuda\")\n",
    "train_loader = DataLoader(TensorDataset(Xtr, Ytr), batch_size=16, shuffle=True,\n",
    "                          pin_memory=pin, num_workers=0)\n",
    "val_loader   = DataLoader(TensorDataset(Xva, Yva), batch_size=64, shuffle=False,\n",
    "                          pin_memory=pin, num_workers=0)\n",
    "test_loader  = DataLoader(TensorDataset(Xte, Yte), batch_size=64, shuffle=False,\n",
    "                          pin_memory=pin, num_workers=0)\n",
    "\n",
    "print(\"Hazır: train/val/test loader (CPU → GPU transfer DataLoader içinde yapılacak)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1dfbb7-7b8c-4f82-aa8a-24f2316ad55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightning GPU device hazır.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_qubits = 4\n",
    "n_layers = 6\n",
    "\n",
    "dev = qml.device(\n",
    "    \"lightning.gpu\",\n",
    "    wires=n_qubits,\n",
    "    shots=None,            \n",
    "    c_dtype=np.complex128, \n",
    ")\n",
    "\n",
    "def ROT_layer(w, n):\n",
    "    for i in range(n):\n",
    "        qml.Rot(*w[i], wires=i)\n",
    "\n",
    "def U3_layer(w, n):\n",
    "    for i in range(n):\n",
    "        qml.U3(*w[i], wires=i)\n",
    "\n",
    "def strong_entangling_layer(n):\n",
    "    for i in range(n-1):\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "    qml.CNOT(wires=[n-1, 0])\n",
    "\n",
    "print(\"Lightning GPU device hazır.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e0157e-1c68-4996-a9ab-f78184ed169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"adjoint\")\n",
    "def qnode(inputs, weights_1, weights_2):\n",
    "    \n",
    "    qml.AmplitudeEmbedding(features=inputs, wires=range(n_qubits), normalize=True)\n",
    "    for k in range(n_layers):\n",
    "        U3_layer(weights_1[k], n_qubits)\n",
    "        strong_entangling_layer(n_qubits)\n",
    "        ROT_layer(weights_2[k], n_qubits)\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "weight_shapes = {\n",
    "    \"weights_1\": (n_layers, n_qubits, 3),\n",
    "    \"weights_2\": (n_layers, n_qubits, 3),\n",
    "}\n",
    "\n",
    "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69449f44-138b-44e3-bdd7-a7c962b11906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VQNNModel(\n",
      "  (q): <Quantum Torch Layer: func=qnode>\n",
      "  (fc): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class VQNNModel(nn.Module):\n",
    "    def __init__(self, nq):\n",
    "        super().__init__()\n",
    "        self.q = qlayer           \n",
    "        self.fc = nn.Linear(2*nq, 1)  \n",
    "    def forward(self, x):\n",
    "        x1 = self.q(x)\n",
    "        x2 = self.q(x**2)\n",
    "        x  = torch.cat([x1, x2], dim=1)\n",
    "        x  = F.relu(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = VQNNModel(n_qubits).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26aa0af8-067b-44b8-86f9-6fa87d652f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] Train MAE=3.185502 | Val MAE=4.014114 | Best=4.014114@001 | Time=1248.04s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 002] Train MAE=2.823982 | Val MAE=3.735874 | Best=3.735874@002 | Time=1820.39s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 003] Train MAE=2.566554 | Val MAE=3.501042 | Best=3.501042@003 | Time=1793.07s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 004] Train MAE=2.361026 | Val MAE=3.300656 | Best=3.300656@004 | Time=1799.10s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 005] Train MAE=2.210426 | Val MAE=3.128414 | Best=3.128414@005 | Time=1900.42s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 006] Train MAE=2.105864 | Val MAE=2.979765 | Best=2.979765@006 | Time=1819.59s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 007] Train MAE=2.025911 | Val MAE=2.836059 | Best=2.836059@007 | Time=1823.28s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 008] Train MAE=1.962833 | Val MAE=2.726708 | Best=2.726708@008 | Time=1598.31s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 009] Train MAE=1.907195 | Val MAE=2.622002 | Best=2.622002@009 | Time=1621.98s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 010] Train MAE=1.861819 | Val MAE=2.530631 | Best=2.530631@010 | Time=1628.05s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 011] Train MAE=1.820027 | Val MAE=2.452422 | Best=2.452422@011 | Time=1632.02s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 012] Train MAE=1.786876 | Val MAE=2.382509 | Best=2.382509@012 | Time=1629.72s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 013] Train MAE=1.751922 | Val MAE=2.329612 | Best=2.329612@013 | Time=1626.73s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 014] Train MAE=1.722636 | Val MAE=2.283529 | Best=2.283529@014 | Time=1628.64s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 015] Train MAE=1.696433 | Val MAE=2.237320 | Best=2.237320@015 | Time=1627.00s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 016] Train MAE=1.672326 | Val MAE=2.193883 | Best=2.193883@016 | Time=1627.68s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 017] Train MAE=1.647871 | Val MAE=2.176452 | Best=2.176452@017 | Time=1622.05s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 018] Train MAE=1.629196 | Val MAE=2.161915 | Best=2.161915@018 | Time=1627.67s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 019] Train MAE=1.610375 | Val MAE=2.112474 | Best=2.112474@019 | Time=1632.03s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 020] Train MAE=1.595321 | Val MAE=2.092709 | Best=2.092709@020 | Time=1631.65s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 021] Train MAE=1.578486 | Val MAE=2.082836 | Best=2.082836@021 | Time=1624.41s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 022] Train MAE=1.561082 | Val MAE=2.048136 | Best=2.048136@022 | Time=1618.12s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 023] Train MAE=1.541131 | Val MAE=2.026941 | Best=2.026941@023 | Time=1638.42s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 024] Train MAE=1.524149 | Val MAE=2.002584 | Best=2.002584@024 | Time=1636.11s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 025] Train MAE=1.501599 | Val MAE=2.000628 | Best=2.000628@025 | Time=1625.64s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 026] Train MAE=1.488046 | Val MAE=1.974097 | Best=1.974097@026 | Time=1624.92s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 027] Train MAE=1.460225 | Val MAE=1.946306 | Best=1.946306@027 | Time=1614.73s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 028] Train MAE=1.438019 | Val MAE=1.940565 | Best=1.940565@028 | Time=1626.86s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 029] Train MAE=1.420218 | Val MAE=1.940183 | Best=1.940183@029 | Time=1624.14s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 030] Train MAE=1.400149 | Val MAE=1.903144 | Best=1.903144@030 | Time=1628.15s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 031] Train MAE=1.383843 | Val MAE=1.914527 | Best=1.903144@030 | Time=1623.92s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 032] Train MAE=1.364504 | Val MAE=1.885852 | Best=1.885852@032 | Time=1337.14s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 033] Train MAE=1.344680 | Val MAE=1.883329 | Best=1.883329@033 | Time=944.45s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 034] Train MAE=1.324781 | Val MAE=1.892068 | Best=1.883329@033 | Time=934.01s | GPU~16.3MB | LR=1.00e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     49\u001b[0m     start_t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 51\u001b[0m     tr \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     va \u001b[38;5;241m=\u001b[39m run_epoch(val_loader,   train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(va)\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(loader, train)\u001b[0m\n\u001b[1;32m     21\u001b[0m     yb \u001b[38;5;241m=\u001b[39m yb\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m loss  \u001b[38;5;241m=\u001b[39m loss_fn(preds, yb)\n\u001b[1;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mVQNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 8\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq(x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     10\u001b[0m     x  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x1, x2], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/qnn/torch.py:408\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    405\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(inputs, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# calculate the forward pass as usual\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_batch_dim:\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/qnn/torch.py:434\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{arg: weight\u001b[38;5;241m.\u001b[39mto(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m    433\u001b[0m }\n\u001b[0;32m--> 434\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqnode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/qnode.py:922\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_capture_qnode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/qnode.py:895\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_program\u001b[38;5;241m.\u001b[39mset_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m--> 895\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/execution.py:233\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, transform_program, executor_backend)\u001b[0m\n\u001b[1;32m    229\u001b[0m tapes, outer_post_processing \u001b[38;5;241m=\u001b[39m outer_transform(tapes)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outer_transform\u001b[38;5;241m.\u001b[39mis_informative, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould only contain device preprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_post_processing(outer_post_processing(results))\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/run.py:338\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    335\u001b[0m         params \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    336\u001b[0m         tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_trainable_indices(params)\n\u001b[0;32m--> 338\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mml_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:240\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, execute_fn, jpc, device)\u001b[0m\n\u001b[1;32m    232\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mextend(tape\u001b[38;5;241m.\u001b[39mget_parameters())\n\u001b[1;32m    234\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(tapes),\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecute_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: execute_fn,\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m: jpc,\n\u001b[1;32m    238\u001b[0m }\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExecuteTapes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:89\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_apply\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_apply\u001b[39m(\u001b[38;5;241m*\u001b[39minp):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Inputs already flat\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     out_struct_holder \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 89\u001b[0m     flat_out \u001b[38;5;241m=\u001b[39m \u001b[43morig_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_struct_holder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_out, out_struct_holder[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:93\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_forward\u001b[0;34m(ctx, out_struct_holder, *inp)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(ctx, out_struct_holder, \u001b[38;5;241m*\u001b[39minp):\n\u001b[0;32m---> 93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43morig_fw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     flat_out, out_struct \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_flatten(out)\n\u001b[1;32m     95\u001b[0m     ctx\u001b[38;5;241m.\u001b[39m_out_struct \u001b[38;5;241m=\u001b[39m out_struct\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:162\u001b[0m, in \u001b[0;36mExecuteTapes.forward\u001b[0;34m(ctx, kwargs, *parameters)\u001b[0m\n\u001b[1;32m    159\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtapes \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m ctx\u001b[38;5;241m.\u001b[39mjpc \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 162\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# if any input tensor uses the GPU, the output should as well\u001b[39;00m\n\u001b[1;32m    165\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtorch_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/jacobian_products.py:487\u001b[0m, in \u001b[0;36mDeviceDerivatives.execute_and_cache_jacobian\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger\u001b[38;5;241m.\u001b[39misEnabledFor(logging\u001b[38;5;241m.\u001b[39mDEBUG):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward pass called with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, tapes)\n\u001b[0;32m--> 487\u001b[0m results, jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dev_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results_cache[tapes] \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jacs_cache[tapes] \u001b[38;5;241m=\u001b[39m jac\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/jacobian_products.py:452\u001b[0m, in \u001b[0;36mDeviceDerivatives._dev_execute_and_compute_derivatives\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03mConverts tapes to numpy before computing the the results and derivatives on the device.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03mDispatches between the two different device interfaces.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    451\u001b[0m numpy_tapes, _ \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mconvert_to_numpy_parameters(tapes)\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_device\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumpy_tapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/devices/modifiers/simulator_tracking.py:95\u001b[0m, in \u001b[0;36m_track_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m     90\u001b[0m         execute_and_derivative_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     91\u001b[0m         executions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     92\u001b[0m         derivatives\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muntracked_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/devices/modifiers/single_tape_support.py:60\u001b[0m, in \u001b[0;36m_make_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     58\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[0;32m---> 60\u001b[0m results, jacs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (results[\u001b[38;5;241m0\u001b[39m], jacs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m (results, jacs)\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/devices/modifiers/simulator_tracking.py:95\u001b[0m, in \u001b[0;36m_track_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m     90\u001b[0m         execute_and_derivative_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     91\u001b[0m         executions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     92\u001b[0m         derivatives\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muntracked_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/devices/modifiers/single_tape_support.py:60\u001b[0m, in \u001b[0;36m_make_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     58\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[0;32m---> 60\u001b[0m results, jacs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (results[\u001b[38;5;241m0\u001b[39m], jacs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m (results, jacs)\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane_lightning/lightning_base/lightning_base.py:451\u001b[0m, in \u001b[0;36mLightningBase.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the results and jacobians of circuits at the same time.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Tuple: A numeric result of the computation and the gradient.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m batch_obs \u001b[38;5;241m=\u001b[39m execution_config\u001b[38;5;241m.\u001b[39mdevice_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_obs)\n\u001b[0;32m--> 451\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_and_jacobian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamic_wires_from_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statevector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwire_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wire_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults))\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane_lightning/lightning_base/lightning_base.py:452\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the results and jacobians of circuits at the same time.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Tuple: A numeric result of the computation and the gradient.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m batch_obs \u001b[38;5;241m=\u001b[39m execution_config\u001b[38;5;241m.\u001b[39mdevice_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_obs)\n\u001b[1;32m    451\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_and_jacobian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamic_wires_from_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statevector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwire_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wire_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m circuit \u001b[38;5;129;01min\u001b[39;00m circuits\n\u001b[1;32m    459\u001b[0m )\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults))\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane_lightning/lightning_base/lightning_base.py:342\u001b[0m, in \u001b[0;36mLightningBase.simulate_and_jacobian\u001b[0;34m(self, circuit, state, batch_obs, wire_map)\u001b[0m\n\u001b[1;32m    340\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulate(circuit, state)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLightningAdjointJacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_obs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res, jac\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane_lightning/lightning_gpu/_adjoint_jacobian.py:161\u001b[0m, in \u001b[0;36mLightningGPUAdjointJacobian.calculate_jacobian\u001b[0;34m(self, tape)\u001b[0m\n\u001b[1;32m    154\u001b[0m     jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jacobian_lightning\u001b[38;5;241m.\u001b[39mbatched(\n\u001b[1;32m    155\u001b[0m         processed_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    156\u001b[0m         processed_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_serialized\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    157\u001b[0m         processed_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mops_serialized\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    158\u001b[0m         trainable_params,\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jacobian_lightning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_vector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobs_serialized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mops_serialized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m jac \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(jac)\n\u001b[1;32m    169\u001b[0m has_shape0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mlen\u001b[39m(jac))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn   = nn.L1Loss()  # MAE\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=5, min_lr=1e-5\n",
    ")\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    if train:\n",
    "        model.train(True)\n",
    "    else:\n",
    "        model.train(False)\n",
    "\n",
    "    total, count = 0.0, 0\n",
    "    if train:\n",
    "        for xb, yb in loader:\n",
    "            if device.type == \"cuda\":\n",
    "                xb = xb.to(device, non_blocking=True)\n",
    "                yb = yb.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            preds = model(xb)\n",
    "            loss  = loss_fn(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += loss.item() * xb.size(0)\n",
    "            count += xb.size(0)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in loader:\n",
    "                if device.type == \"cuda\":\n",
    "                    xb = xb.to(device, non_blocking=True)\n",
    "                    yb = yb.to(device, non_blocking=True)\n",
    "                preds = model(xb)\n",
    "                loss  = loss_fn(preds, yb)\n",
    "                total += loss.item() * xb.size(0)\n",
    "                count += xb.size(0)\n",
    "    return total / max(count, 1)\n",
    "\n",
    "EPOCHS   = 100\n",
    "PATIENCE = 10\n",
    "best_val = float(\"inf\")\n",
    "best_ep  = -1\n",
    "no_impr  = 0\n",
    "best_state = None\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    start_t = time.time()\n",
    "\n",
    "    tr = run_epoch(train_loader, train=True)\n",
    "    va = run_epoch(val_loader,   train=False)\n",
    "\n",
    "    scheduler.step(va)\n",
    "    last_lr = scheduler._last_lr[0] if hasattr(scheduler, \"_last_lr\") else optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    # en iyi model kaydı\n",
    "    if va < best_val - 1e-9:\n",
    "        best_val  = va\n",
    "        best_ep   = ep\n",
    "        no_impr   = 0\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    else:\n",
    "        no_impr += 1\n",
    "\n",
    "    elapsed = time.time() - start_t\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "        mem_mb = torch.cuda.memory_allocated() / (1024**2)\n",
    "        print(f\"[Epoch {ep:03d}] Train MAE={tr:.6f} | Val MAE={va:.6f} \"\n",
    "              f\"| Best={best_val:.6f}@{best_ep:03d} | Time={elapsed:.2f}s \"\n",
    "              f\"| GPU~{mem_mb:.1f}MB | LR={last_lr:.2e}\")\n",
    "    else:\n",
    "        print(f\"[Epoch {ep:03d}] Train MAE={tr:.6f} | Val MAE={va:.6f} \"\n",
    "              f\"| Best={best_val:.6f}@{best_ep:03d} | Time={elapsed:.2f}s \"\n",
    "              f\"| LR={last_lr:.2e}\")\n",
    "\n",
    "    if no_impr >= PATIENCE:\n",
    "        print(f\"⛳ Early stopping: {PATIENCE} epoch iyileşme yok (son en iyi {best_ep}. epoch).\")\n",
    "        break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device).eval()\n",
    "    print(f\"✓ En iyi val MAE = {best_val:.6f} @ epoch {best_ep}\")\n",
    "else:\n",
    "    print(\"Uyarı: hiç iyileşme kaydedilmedi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f87e98e3-b782-4cf0-925f-a7a72741e422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gerçek en iyi ağırlıklar kaydedildi: best_ampmodel_weights.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assert best_state is not None, \"best_state boş; eğitim boyunca hiç iyileşme olmamış olabilir.\"\n",
    "\n",
    "model.load_state_dict(best_state) \n",
    "model.eval()\n",
    "torch.save(model.state_dict(), \"best_ampmodel_weights.pth\")\n",
    "print(\"✓ Gerçek en iyi ağırlıklar kaydedildi: best_ampmodel_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ee87186-9a17-4f9e-8679-3558326c68cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test MAE: 1.612947630521802\n",
      "Best Test MSE: 5.661935281993452\n",
      "Best Test R^2: 0.5716822834942471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        if device.type == \"cuda\":\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "        y_pred.append(model(xb).cpu().numpy().ravel())\n",
    "        y_true.append(yb.cpu().numpy().ravel())\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "y_pred = np.concatenate(y_pred); y_true = np.concatenate(y_true)\n",
    "\n",
    "print(\"Best Test MAE:\", metrics.mean_absolute_error(y_true, y_pred))\n",
    "print(\"Best Test MSE:\", metrics.mean_squared_error(y_true, y_pred))\n",
    "print(\"Best Test R^2:\",  metrics.r2_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d22dd-c722-4aa7-9f83-c044c933142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(\"best_ampmodel_weights.pth\", map_location=device))\n",
    "#model.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b4a2e-0ddc-41d8-ae73-803836a25d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "252103de-c9fa-4af7-8d51-1646e35718a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanılan kolonlar: ['BW', 'COMED', 'DOSE', 'TIME', 'EVID', 'MDV', 'AMT', 'CMT', 'DVID']\n",
      "Tahmin DV (Amplitude, 4 qubit): 6.384136\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    feature_cols = FEATURES         \n",
    "except NameError:\n",
    "    feature_cols = [\"BW\", \"COMED\", \"DOSE\", \"TIME\", \"EVID\", \"MDV\", \"AMT\", \"CMT\", \"DVID\"]\n",
    "\n",
    "print(\"Kullanılan kolonlar:\", feature_cols)\n",
    "\n",
    "sample = {\n",
    "    \"BW\":   70.0,\n",
    "    \"COMED\":0.0,\n",
    "    \"DOSE\": 1.0,\n",
    "    \"TIME\": 488.0,\n",
    "    \"EVID\": 0.0,\n",
    "    \"MDV\":  0.0,\n",
    "    \"AMT\":  0.0,\n",
    "    \"CMT\":  3.0,\n",
    "    \"DVID\": 2.0,\n",
    "}\n",
    "\n",
    "sample_df = pd.DataFrame([sample], columns=feature_cols).astype(np.float64)\n",
    "\n",
    "eps_local = 1e-8 if 'eps' not in globals() else float(eps)\n",
    "x = sample_df.to_numpy(dtype=np.float64)                      \n",
    "x_std = (x - mean_.astype(np.float64)) / (std_.astype(np.float64) + eps_local)\n",
    "\n",
    "AMP_DIM = 16\n",
    "if x_std.shape[1] > AMP_DIM:\n",
    "    raise ValueError(f\"Giriş {x_std.shape[1]} > {AMP_DIM}. Amplitude için 2^n boyuta indirmen gerek.\")\n",
    "pad = np.zeros((1, AMP_DIM - x_std.shape[1]), dtype=np.float64)\n",
    "x_amp = np.concatenate([x_std, pad], axis=1)                   \n",
    "\n",
    "xb = torch.from_numpy(x_amp)\n",
    "if device.type == \"cuda\":\n",
    "    xb = xb.to(device, non_blocking=True)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = model(xb).item()\n",
    "\n",
    "print(f\"Tahmin DV (Amplitude, 4 qubit): {y_hat:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb698df8-1523-4c73-b494-353e4814e1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vqnn-yenv)",
   "language": "python",
   "name": "vqnn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
