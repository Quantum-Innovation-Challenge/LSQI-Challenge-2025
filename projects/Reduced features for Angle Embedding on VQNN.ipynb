{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3cde6d2-cef8-4c2a-b3b5-b3efaa790353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES = None\n",
      "PyTorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn import metrics\n",
    "import pennylane as qml\n",
    "\n",
    "print(\"CUDA_VISIBLE_DEVICES =\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"PyTorch device:\", device)\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e68b83b-52ca-47cf-9059-127a006b29a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satır: 2820 | Özellik sayısı: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>BW</th>\n",
       "      <th>COMED</th>\n",
       "      <th>DOSE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DV</th>\n",
       "      <th>EVID</th>\n",
       "      <th>MDV</th>\n",
       "      <th>AMT</th>\n",
       "      <th>CMT</th>\n",
       "      <th>DVID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.6174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.7783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  BW  COMED  DOSE  TIME       DV  EVID  MDV  AMT  CMT  DVID\n",
       "0   1  58      0     0     0  18.6174     0    0    0    3     2\n",
       "1   1  58      0     0     1  13.7783     0    0    0    3     2\n",
       "2   1  58      0     0     2  16.5747     0    0    0    3     2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_PATH = \"QIC2025-EstDat.csv\"\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    alt = \"QIC2025-EstDat (1).csv\"\n",
    "    if os.path.exists(alt):\n",
    "        CSV_PATH = alt\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "TARGET   = \"DV\"\n",
    "FEATURES = [\"BW\",\"COMED\",\"DOSE\",\"TIME\",\"EVID\",\"MDV\",\"AMT\",\"CMT\",\"DVID\"]\n",
    "df = df.dropna(subset=FEATURES + [TARGET]).copy()\n",
    "\n",
    "print(\"Satır:\", len(df), \"| Özellik sayısı:\", len(FEATURES))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5393e7eb-aa62-40af-9d1a-395b1a16b529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test şekilleri: (2040, 11) (355, 11) (425, 11)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "uids = df[\"ID\"].unique().copy()\n",
    "rng.shuffle(uids)\n",
    "\n",
    "n_total = len(uids)\n",
    "n_train = int(0.70 * n_total)\n",
    "n_val   = int(0.15 * n_total)\n",
    "\n",
    "train_ids = uids[:n_train]\n",
    "val_ids   = uids[n_train:n_train+n_val]\n",
    "test_ids  = uids[n_train+n_val:]\n",
    "\n",
    "train_df = df[df[\"ID\"].isin(train_ids)].copy()\n",
    "val_df   = df[df[\"ID\"].isin(val_ids)].copy()\n",
    "test_df  = df[df[\"ID\"].isin(test_ids)].copy()\n",
    "\n",
    "\n",
    "print(\"Train/Val/Test şekilleri:\", train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf10002-dd2d-4666-97fa-99d2dd2a9e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI skorları: {'BW': 0.3037416872147447, 'COMED': 0.04074290033175565, 'DOSE': 0.23695951682639427, 'TIME': 0.4901808746020251, 'EVID': 0.592286523888653, 'MDV': 0.5807141068924297, 'AMT': 0.59223657912797, 'CMT': 0.7974154220004936, 'DVID': 0.8059427019699386}\n",
      "Seçilen TOP3: ['DVID', 'CMT', 'EVID']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "X_train_raw = train_df[FEATURES].to_numpy(dtype=np.float64)\n",
    "y_train_raw = train_df[TARGET].to_numpy(dtype=np.float64)\n",
    "\n",
    "scaler_mi = StandardScaler().fit(X_train_raw)\n",
    "X_train_std = scaler_mi.transform(X_train_raw)\n",
    "\n",
    "mi = mutual_info_regression(X_train_std, y_train_raw, random_state=42)\n",
    "top_idx = np.argsort(mi)[::-1][:3]\n",
    "TOP3_FEATURES = [FEATURES[i] for i in top_idx]\n",
    "\n",
    "print(\"MI skorları:\", dict(zip(FEATURES, mi)))\n",
    "print(\"Seçilen TOP3:\", TOP3_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96aa0cc1-8031-41c5-b169-3a54a1eb6ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (top-3, no pad): (2040, 3) (355, 3) (425, 3)\n"
     ]
    }
   ],
   "source": [
    "FEATURES_USED = TOP3_FEATURES\n",
    "X_train = train_df[FEATURES_USED].to_numpy(dtype=np.float64)\n",
    "X_val   = val_df[FEATURES_USED].to_numpy(dtype=np.float64)\n",
    "X_test  = test_df[FEATURES_USED].to_numpy(dtype=np.float64)\n",
    "\n",
    "y_train = train_df[TARGET].to_numpy(dtype=np.float64)\n",
    "y_val   = val_df[TARGET].to_numpy(dtype=np.float64)\n",
    "y_test  = test_df[TARGET].to_numpy(dtype=np.float64)\n",
    "\n",
    "mean_ = X_train.mean(axis=0, keepdims=True)\n",
    "std_  = X_train.std(axis=0, keepdims=True)\n",
    "std_[std_ == 0] = 1.0\n",
    "eps = 1e-8\n",
    "\n",
    "def zscore(x): return (x - mean_) / (std_ + eps)\n",
    "\n",
    "TrainX = zscore(X_train).astype(np.float64)  # (N, 3)\n",
    "ValX   = zscore(X_val).astype(np.float64)    # (N, 3)\n",
    "TestX  = zscore(X_test).astype(np.float64)   # (N, 3)\n",
    "\n",
    "print(\"Shapes (top-3, no pad):\", TrainX.shape, ValX.shape, TestX.shape)  # (..., 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1958fbb2-0a2d-4909-ac8b-ab8bb982876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = torch.from_numpy(TrainX)                \n",
    "Ytr = torch.from_numpy(y_train.reshape(-1,1))\n",
    "Xva = torch.from_numpy(ValX)\n",
    "Yva = torch.from_numpy(y_val.reshape(-1,1))\n",
    "Xte = torch.from_numpy(TestX)\n",
    "Yte = torch.from_numpy(y_test.reshape(-1,1))\n",
    "\n",
    "pin = (device.type == \"cuda\")\n",
    "train_loader = DataLoader(TensorDataset(Xtr, Ytr), batch_size=32, shuffle=True,\n",
    "                          pin_memory=pin, num_workers=0)\n",
    "val_loader   = DataLoader(TensorDataset(Xva, Yva), batch_size=128, shuffle=False,\n",
    "                          pin_memory=pin, num_workers=0)\n",
    "test_loader  = DataLoader(TensorDataset(Xte, Yte), batch_size=128, shuffle=False,\n",
    "                          pin_memory=pin, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b1dfbb7-7b8c-4f82-aa8a-24f2316ad55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_qubits = 3\n",
    "n_layers = 3  \n",
    "\n",
    "dev = qml.device(\n",
    "    \"lightning.gpu\",\n",
    "    wires=n_qubits,\n",
    "    shots=None,\n",
    "    c_dtype=np.complex128,\n",
    ")\n",
    "\n",
    "def ROT_layer(w, n):\n",
    "    for i in range(n): qml.Rot(*w[i], wires=i)\n",
    "\n",
    "def U3_layer(w, n):\n",
    "    for i in range(n): qml.U3(*w[i], wires=i)\n",
    "\n",
    "def strong_entangling_layer(n):\n",
    "    for i in range(n-1): qml.CNOT(wires=[i, i+1])\n",
    "    qml.CNOT(wires=[n-1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2e0157e-1c68-4996-a9ab-f78184ed169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"adjoint\")\n",
    "def qnode(inputs, weights_1, weights_2):\n",
    "    qml.AngleEmbedding(features=inputs, wires=range(n_qubits), rotation='Y')\n",
    "    for k in range(n_layers):\n",
    "        U3_layer(weights_1[k], n_qubits)\n",
    "        strong_entangling_layer(n_qubits)\n",
    "        ROT_layer(weights_2[k], n_qubits)\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "weight_shapes = {\n",
    "    \"weights_1\": (n_layers, n_qubits, 3),\n",
    "    \"weights_2\": (n_layers, n_qubits, 3),\n",
    "}\n",
    "\n",
    "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69449f44-138b-44e3-bdd7-a7c962b11906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VQNNModel(\n",
      "  (q): <Quantum Torch Layer: func=qnode>\n",
      "  (fc): Linear(in_features=6, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class VQNNModel(nn.Module):\n",
    "    def __init__(self, nq, two_branches=True):\n",
    "        super().__init__()\n",
    "        self.q = qlayer\n",
    "        self.two_branches = two_branches\n",
    "        in_dim = 2*nq if two_branches else nq\n",
    "        self.fc = nn.Linear(in_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.q(x)                 # (B,3)\n",
    "        if self.two_branches:\n",
    "            x2 = self.q(x**2)          # ikinci QNode çağrısı → maliyet 2x\n",
    "            x  = torch.cat([x1, x2], dim=1)  # (B,6)\n",
    "        else:\n",
    "            x = x1                      # (B,3)\n",
    "        x = F.relu(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = VQNNModel(n_qubits, two_branches=True).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26aa0af8-067b-44b8-86f9-6fa87d652f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] Train MAE=3.323119 | Val MAE=4.293767 | Best=4.293767@001 | Time=540.98s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 002] Train MAE=3.235820 | Val MAE=4.178942 | Best=4.178942@002 | Time=565.68s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 003] Train MAE=3.092115 | Val MAE=3.996053 | Best=3.996053@003 | Time=538.02s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 004] Train MAE=2.916706 | Val MAE=3.792280 | Best=3.792280@004 | Time=538.39s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 005] Train MAE=2.692304 | Val MAE=3.551418 | Best=3.551418@005 | Time=569.06s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 006] Train MAE=2.495499 | Val MAE=3.375116 | Best=3.375116@006 | Time=542.30s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 007] Train MAE=2.355198 | Val MAE=3.220464 | Best=3.220464@007 | Time=541.00s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 008] Train MAE=2.246399 | Val MAE=3.091517 | Best=3.091517@008 | Time=570.50s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 009] Train MAE=2.157647 | Val MAE=2.977231 | Best=2.977231@009 | Time=548.95s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 010] Train MAE=2.086384 | Val MAE=2.877341 | Best=2.877341@010 | Time=543.46s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 011] Train MAE=2.027121 | Val MAE=2.777240 | Best=2.777240@011 | Time=564.93s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 012] Train MAE=1.976809 | Val MAE=2.697293 | Best=2.697293@012 | Time=544.72s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 013] Train MAE=1.931826 | Val MAE=2.614121 | Best=2.614121@013 | Time=548.74s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 014] Train MAE=1.891111 | Val MAE=2.540531 | Best=2.540531@014 | Time=560.63s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 015] Train MAE=1.855234 | Val MAE=2.463350 | Best=2.463350@015 | Time=543.13s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 016] Train MAE=1.822496 | Val MAE=2.386965 | Best=2.386965@016 | Time=545.60s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 017] Train MAE=1.793901 | Val MAE=2.330913 | Best=2.330913@017 | Time=563.87s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 018] Train MAE=1.767721 | Val MAE=2.263304 | Best=2.263304@018 | Time=543.26s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 019] Train MAE=1.742176 | Val MAE=2.200662 | Best=2.200662@019 | Time=544.94s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 020] Train MAE=1.720648 | Val MAE=2.147991 | Best=2.147991@020 | Time=572.99s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 021] Train MAE=1.699140 | Val MAE=2.104435 | Best=2.104435@021 | Time=542.45s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 022] Train MAE=1.681149 | Val MAE=2.060445 | Best=2.060445@022 | Time=542.85s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 023] Train MAE=1.666326 | Val MAE=2.034330 | Best=2.034330@023 | Time=563.77s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 024] Train MAE=1.653353 | Val MAE=1.992547 | Best=1.992547@024 | Time=540.34s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 025] Train MAE=1.641765 | Val MAE=1.950115 | Best=1.950115@025 | Time=546.20s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 026] Train MAE=1.632369 | Val MAE=1.924697 | Best=1.924697@026 | Time=567.07s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 027] Train MAE=1.622589 | Val MAE=1.904211 | Best=1.904211@027 | Time=544.04s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 028] Train MAE=1.615690 | Val MAE=1.881626 | Best=1.881626@028 | Time=541.38s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 029] Train MAE=1.609229 | Val MAE=1.858726 | Best=1.858726@029 | Time=564.60s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 030] Train MAE=1.602955 | Val MAE=1.838512 | Best=1.838512@030 | Time=539.96s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 031] Train MAE=1.598612 | Val MAE=1.820799 | Best=1.820799@031 | Time=541.08s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 032] Train MAE=1.594820 | Val MAE=1.810082 | Best=1.810082@032 | Time=571.66s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 033] Train MAE=1.592427 | Val MAE=1.801302 | Best=1.801302@033 | Time=543.15s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 034] Train MAE=1.590155 | Val MAE=1.787291 | Best=1.787291@034 | Time=546.66s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 035] Train MAE=1.588717 | Val MAE=1.784409 | Best=1.784409@035 | Time=564.79s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 036] Train MAE=1.586776 | Val MAE=1.774417 | Best=1.774417@036 | Time=544.68s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 037] Train MAE=1.585067 | Val MAE=1.773819 | Best=1.773819@037 | Time=546.29s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 038] Train MAE=1.584606 | Val MAE=1.765552 | Best=1.765552@038 | Time=566.17s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 039] Train MAE=1.583619 | Val MAE=1.751510 | Best=1.751510@039 | Time=540.03s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 040] Train MAE=1.582509 | Val MAE=1.753776 | Best=1.751510@039 | Time=547.63s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 041] Train MAE=1.582080 | Val MAE=1.750733 | Best=1.750733@041 | Time=567.12s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 042] Train MAE=1.581462 | Val MAE=1.745226 | Best=1.745226@042 | Time=537.95s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 043] Train MAE=1.581374 | Val MAE=1.739309 | Best=1.739309@043 | Time=543.96s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 044] Train MAE=1.580758 | Val MAE=1.741996 | Best=1.739309@043 | Time=569.32s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 045] Train MAE=1.580522 | Val MAE=1.736614 | Best=1.736614@045 | Time=547.13s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 046] Train MAE=1.579828 | Val MAE=1.735258 | Best=1.735258@046 | Time=547.10s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 047] Train MAE=1.580111 | Val MAE=1.735173 | Best=1.735173@047 | Time=559.08s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 048] Train MAE=1.580243 | Val MAE=1.731814 | Best=1.731814@048 | Time=544.94s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 049] Train MAE=1.579777 | Val MAE=1.733513 | Best=1.731814@048 | Time=562.05s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 050] Train MAE=1.579649 | Val MAE=1.728813 | Best=1.728813@050 | Time=559.89s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 051] Train MAE=1.579478 | Val MAE=1.728758 | Best=1.728758@051 | Time=543.57s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 052] Train MAE=1.579628 | Val MAE=1.727870 | Best=1.727870@052 | Time=554.69s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 053] Train MAE=1.580495 | Val MAE=1.723319 | Best=1.723319@053 | Time=552.33s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 054] Train MAE=1.579555 | Val MAE=1.724473 | Best=1.723319@053 | Time=544.82s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 055] Train MAE=1.579435 | Val MAE=1.724061 | Best=1.723319@053 | Time=554.05s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 056] Train MAE=1.579286 | Val MAE=1.725024 | Best=1.723319@053 | Time=548.32s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 057] Train MAE=1.579424 | Val MAE=1.725284 | Best=1.723319@053 | Time=539.46s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 058] Train MAE=1.579396 | Val MAE=1.723073 | Best=1.723073@058 | Time=557.75s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 059] Train MAE=1.579489 | Val MAE=1.725946 | Best=1.723073@058 | Time=541.99s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 060] Train MAE=1.579333 | Val MAE=1.724377 | Best=1.723073@058 | Time=543.86s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 061] Train MAE=1.579337 | Val MAE=1.725653 | Best=1.723073@058 | Time=563.70s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 062] Train MAE=1.579496 | Val MAE=1.723059 | Best=1.723059@062 | Time=536.70s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 063] Train MAE=1.579342 | Val MAE=1.722543 | Best=1.722543@063 | Time=547.10s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 064] Train MAE=1.579679 | Val MAE=1.722585 | Best=1.722543@063 | Time=565.82s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 065] Train MAE=1.579489 | Val MAE=1.722306 | Best=1.722306@065 | Time=542.27s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 066] Train MAE=1.579482 | Val MAE=1.722402 | Best=1.722306@065 | Time=544.21s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 067] Train MAE=1.579865 | Val MAE=1.723721 | Best=1.722306@065 | Time=568.94s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 068] Train MAE=1.579858 | Val MAE=1.721865 | Best=1.721865@068 | Time=540.07s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 069] Train MAE=1.579303 | Val MAE=1.723144 | Best=1.721865@068 | Time=541.84s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 070] Train MAE=1.579186 | Val MAE=1.722729 | Best=1.721865@068 | Time=562.73s | GPU~16.3MB | LR=1.00e-03\n",
      "[Epoch 071] Train MAE=1.579256 | Val MAE=1.723457 | Best=1.721865@068 | Time=540.67s | GPU~16.3MB | LR=1.00e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     49\u001b[0m     start_t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 51\u001b[0m     tr \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     va \u001b[38;5;241m=\u001b[39m run_epoch(val_loader,   train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(va)\n",
      "Cell \u001b[0;32mIn[21], line 23\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(loader, train)\u001b[0m\n\u001b[1;32m     21\u001b[0m     yb \u001b[38;5;241m=\u001b[39m yb\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m loss  \u001b[38;5;241m=\u001b[39m loss_fn(preds, yb)\n\u001b[1;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m, in \u001b[0;36mVQNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 11\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m                 \u001b[38;5;66;03m# (B,3)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtwo_branches:\n\u001b[1;32m     13\u001b[0m         x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq(x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)          \u001b[38;5;66;03m# ikinci QNode çağrısı → maliyet 2x\u001b[39;00m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/qnn/torch.py:408\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    405\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(inputs, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# calculate the forward pass as usual\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_batch_dim:\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/qnn/torch.py:434\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{arg: weight\u001b[38;5;241m.\u001b[39mto(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m    433\u001b[0m }\n\u001b[0;32m--> 434\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqnode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/qnode.py:922\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_capture_qnode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/qnode.py:895\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_program\u001b[38;5;241m.\u001b[39mset_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m--> 895\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/execution.py:233\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, transform_program, executor_backend)\u001b[0m\n\u001b[1;32m    229\u001b[0m tapes, outer_post_processing \u001b[38;5;241m=\u001b[39m outer_transform(tapes)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outer_transform\u001b[38;5;241m.\u001b[39mis_informative, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould only contain device preprocessing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_post_processing(outer_post_processing(results))\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/run.py:338\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    335\u001b[0m         params \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    336\u001b[0m         tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_trainable_indices(params)\n\u001b[0;32m--> 338\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mml_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:240\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, execute_fn, jpc, device)\u001b[0m\n\u001b[1;32m    232\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mextend(tape\u001b[38;5;241m.\u001b[39mget_parameters())\n\u001b[1;32m    234\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(tapes),\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecute_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: execute_fn,\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m: jpc,\n\u001b[1;32m    238\u001b[0m }\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExecuteTapes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:89\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_apply\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_apply\u001b[39m(\u001b[38;5;241m*\u001b[39minp):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Inputs already flat\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     out_struct_holder \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 89\u001b[0m     flat_out \u001b[38;5;241m=\u001b[39m \u001b[43morig_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_struct_holder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_out, out_struct_holder[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:93\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_forward\u001b[0;34m(ctx, out_struct_holder, *inp)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(ctx, out_struct_holder, \u001b[38;5;241m*\u001b[39minp):\n\u001b[0;32m---> 93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43morig_fw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     flat_out, out_struct \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_flatten(out)\n\u001b[1;32m     95\u001b[0m     ctx\u001b[38;5;241m.\u001b[39m_out_struct \u001b[38;5;241m=\u001b[39m out_struct\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:162\u001b[0m, in \u001b[0;36mExecuteTapes.forward\u001b[0;34m(ctx, kwargs, *parameters)\u001b[0m\n\u001b[1;32m    159\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtapes \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m ctx\u001b[38;5;241m.\u001b[39mjpc \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 162\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# if any input tensor uses the GPU, the output should as well\u001b[39;00m\n\u001b[1;32m    165\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtorch_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/jacobian_products.py:487\u001b[0m, in \u001b[0;36mDeviceDerivatives.execute_and_cache_jacobian\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger\u001b[38;5;241m.\u001b[39misEnabledFor(logging\u001b[38;5;241m.\u001b[39mDEBUG):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward pass called with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, tapes)\n\u001b[0;32m--> 487\u001b[0m results, jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dev_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results_cache[tapes] \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jacs_cache[tapes] \u001b[38;5;241m=\u001b[39m jac\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/workflow/jacobian_products.py:452\u001b[0m, in \u001b[0;36mDeviceDerivatives._dev_execute_and_compute_derivatives\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03mConverts tapes to numpy before computing the the results and derivatives on the device.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03mDispatches between the two different device interfaces.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    451\u001b[0m numpy_tapes, _ \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mconvert_to_numpy_parameters(tapes)\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_device\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumpy_tapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/devices/modifiers/simulator_tracking.py:95\u001b[0m, in \u001b[0;36m_track_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m     90\u001b[0m         execute_and_derivative_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     91\u001b[0m         executions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     92\u001b[0m         derivatives\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muntracked_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/devices/modifiers/single_tape_support.py:60\u001b[0m, in \u001b[0;36m_make_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     58\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[0;32m---> 60\u001b[0m results, jacs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (results[\u001b[38;5;241m0\u001b[39m], jacs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m (results, jacs)\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/devices/modifiers/simulator_tracking.py:95\u001b[0m, in \u001b[0;36m_track_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m     90\u001b[0m         execute_and_derivative_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     91\u001b[0m         executions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     92\u001b[0m         derivatives\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muntracked_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane/devices/modifiers/single_tape_support.py:60\u001b[0m, in \u001b[0;36m_make_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     58\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[0;32m---> 60\u001b[0m results, jacs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (results[\u001b[38;5;241m0\u001b[39m], jacs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m (results, jacs)\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane_lightning/lightning_base/lightning_base.py:451\u001b[0m, in \u001b[0;36mLightningBase.execute_and_compute_derivatives\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the results and jacobians of circuits at the same time.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Tuple: A numeric result of the computation and the gradient.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m batch_obs \u001b[38;5;241m=\u001b[39m execution_config\u001b[38;5;241m.\u001b[39mdevice_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_obs)\n\u001b[0;32m--> 451\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_and_jacobian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamic_wires_from_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statevector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwire_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wire_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults))\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane_lightning/lightning_base/lightning_base.py:452\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the results and jacobians of circuits at the same time.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Tuple: A numeric result of the computation and the gradient.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m batch_obs \u001b[38;5;241m=\u001b[39m execution_config\u001b[38;5;241m.\u001b[39mdevice_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_obs)\n\u001b[1;32m    451\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_and_jacobian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamic_wires_from_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statevector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwire_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wire_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m circuit \u001b[38;5;129;01min\u001b[39;00m circuits\n\u001b[1;32m    459\u001b[0m )\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults))\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane_lightning/lightning_base/lightning_base.py:342\u001b[0m, in \u001b[0;36mLightningBase.simulate_and_jacobian\u001b[0;34m(self, circuit, state, batch_obs, wire_map)\u001b[0m\n\u001b[1;32m    340\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulate(circuit, state)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLightningAdjointJacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_obs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res, jac\n",
      "File \u001b[0;32m~/vqnn-env/lib/python3.10/site-packages/pennylane_lightning/lightning_gpu/_adjoint_jacobian.py:161\u001b[0m, in \u001b[0;36mLightningGPUAdjointJacobian.calculate_jacobian\u001b[0;34m(self, tape)\u001b[0m\n\u001b[1;32m    154\u001b[0m     jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jacobian_lightning\u001b[38;5;241m.\u001b[39mbatched(\n\u001b[1;32m    155\u001b[0m         processed_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    156\u001b[0m         processed_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_serialized\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    157\u001b[0m         processed_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mops_serialized\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    158\u001b[0m         trainable_params,\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jacobian_lightning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_vector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobs_serialized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mops_serialized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m jac \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(jac)\n\u001b[1;32m    169\u001b[0m has_shape0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mlen\u001b[39m(jac))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn   = nn.L1Loss()  # MAE\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=5, min_lr=1e-5\n",
    ")\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    if train:\n",
    "        model.train(True)\n",
    "    else:\n",
    "        model.train(False)\n",
    "\n",
    "    total, count = 0.0, 0\n",
    "    if train:\n",
    "        for xb, yb in loader:\n",
    "            if device.type == \"cuda\":\n",
    "                xb = xb.to(device, non_blocking=True)\n",
    "                yb = yb.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            preds = model(xb)\n",
    "            loss  = loss_fn(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += loss.item() * xb.size(0)\n",
    "            count += xb.size(0)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in loader:\n",
    "                if device.type == \"cuda\":\n",
    "                    xb = xb.to(device, non_blocking=True)\n",
    "                    yb = yb.to(device, non_blocking=True)\n",
    "                preds = model(xb)\n",
    "                loss  = loss_fn(preds, yb)\n",
    "                total += loss.item() * xb.size(0)\n",
    "                count += xb.size(0)\n",
    "    return total / max(count, 1)\n",
    "\n",
    "EPOCHS   = 100\n",
    "PATIENCE = 10\n",
    "best_val = float(\"inf\")\n",
    "best_ep  = -1\n",
    "no_impr  = 0\n",
    "best_state = None\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    start_t = time.time()\n",
    "\n",
    "    tr = run_epoch(train_loader, train=True)\n",
    "    va = run_epoch(val_loader,   train=False)\n",
    "\n",
    "    scheduler.step(va)\n",
    "    last_lr = scheduler._last_lr[0] if hasattr(scheduler, \"_last_lr\") else optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    # en iyi model kaydı\n",
    "    if va < best_val - 1e-9:\n",
    "        best_val  = va\n",
    "        best_ep   = ep\n",
    "        no_impr   = 0\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    else:\n",
    "        no_impr += 1\n",
    "\n",
    "    elapsed = time.time() - start_t\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "        mem_mb = torch.cuda.memory_allocated() / (1024**2)\n",
    "        print(f\"[Epoch {ep:03d}] Train MAE={tr:.6f} | Val MAE={va:.6f} \"\n",
    "              f\"| Best={best_val:.6f}@{best_ep:03d} | Time={elapsed:.2f}s \"\n",
    "              f\"| GPU~{mem_mb:.1f}MB | LR={last_lr:.2e}\")\n",
    "    else:\n",
    "        print(f\"[Epoch {ep:03d}] Train MAE={tr:.6f} | Val MAE={va:.6f} \"\n",
    "              f\"| Best={best_val:.6f}@{best_ep:03d} | Time={elapsed:.2f}s \"\n",
    "              f\"| LR={last_lr:.2e}\")\n",
    "\n",
    "    if no_impr >= PATIENCE:\n",
    "        print(f\"⛳ Early stopping: {PATIENCE} epoch iyileşme yok (son en iyi {best_ep}. epoch).\")\n",
    "        break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device).eval()\n",
    "    print(f\"✓ En iyi val MAE = {best_val:.6f} @ epoch {best_ep}\")\n",
    "else:\n",
    "    print(\"Uyarı: hiç iyileşme kaydedilmedi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07228c3b-e661-4d0e-84da-a6efba11c808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Kaydedildi: best_angmodel_weights.pth\n",
      "Test MAE: 1.7569183587209345\n",
      "Test MSE: 7.018200152145982\n",
      "Test R^2: 0.4690826875560583\n"
     ]
    }
   ],
   "source": [
    "BEST_WEIGHTS = \"best_angmodel_weights.pth\"\n",
    "\n",
    "model.eval()\n",
    "\n",
    "torch.save(model.state_dict(), BEST_WEIGHTS)\n",
    "print(f\"✓ Kaydedildi: {BEST_WEIGHTS}\")\n",
    "\n",
    "y_pred, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        if device.type == \"cuda\":\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "        yhat = model(xb).cpu().numpy().ravel()\n",
    "        y_pred.append(yhat)\n",
    "        y_true.append(yb.cpu().numpy().ravel())\n",
    "\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_true = np.concatenate(y_true)\n",
    "\n",
    "print(\"Test MAE:\", metrics.mean_absolute_error(y_true, y_pred))\n",
    "print(\"Test MSE:\", metrics.mean_squared_error(y_true, y_pred))\n",
    "print(\"Test R^2:\",  metrics.r2_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6b1fb40-1dc7-4a23-9862-7b309883ee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gerçek en iyi ağırlıklar kaydedildi: best_angmodel_weights.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assert best_state is not None, \"best_state boş; eğitim boyunca hiç iyileşme olmamış olabilir.\"\n",
    "\n",
    "model.load_state_dict(best_state)   # en iyi epoch'taki ağırlıkları RAM'e al\n",
    "model.eval()\n",
    "torch.save(model.state_dict(), \"best_angmodel_weights.pth\")\n",
    "print(\"✓ Gerçek en iyi ağırlıklar kaydedildi: best_angmodel_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53be6dd2-7fc0-4a9a-a29f-9e2dadc7f490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test MAE: 1.7572272552391448\n",
      "Best Test MSE: 7.015986575060025\n",
      "Best Test R^2: 0.46925014165709367\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        if device.type == \"cuda\":\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "        y_pred.append(model(xb).cpu().numpy().ravel())\n",
    "        y_true.append(yb.cpu().numpy().ravel())\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "y_pred = np.concatenate(y_pred); y_true = np.concatenate(y_true)\n",
    "\n",
    "print(\"Best Test MAE:\", metrics.mean_absolute_error(y_true, y_pred))\n",
    "print(\"Best Test MSE:\", metrics.mean_squared_error(y_true, y_pred))\n",
    "print(\"Best Test R^2:\",  metrics.r2_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca514845-06d7-49fe-b387-1659a19cd716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanılan kolonlar: ['DVID', 'CMT', 'EVID']\n",
      "Tahmin DV: 1.180330\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    feature_cols = FEATURES_USED  \n",
    "except NameError:\n",
    "    feature_cols = FEATURES       \n",
    "\n",
    "print(\"Kullanılan kolonlar:\", feature_cols)\n",
    "\n",
    "sample = {\n",
    "    \"BW\":   100.0,\n",
    "    \"COMED\":1.0,\n",
    "    \"DOSE\": 1.0,\n",
    "    \"TIME\": 480.0,\n",
    "    \"EVID\": 0.0,\n",
    "    \"MDV\":  0.0,\n",
    "    \"AMT\":  0.0,\n",
    "    \"CMT\":  2.0,\n",
    "    \"DVID\": 1.0,\n",
    "}\n",
    "\n",
    "sample_df = pd.DataFrame([sample], columns=feature_cols).astype(np.float64)\n",
    "\n",
    "\n",
    "eps_local = 1e-8 if 'eps' not in globals() else float(eps)\n",
    "x = sample_df.to_numpy(dtype=np.float64)                           \n",
    "x_std = (x - mean_.astype(np.float64)) / (std_.astype(np.float64) + eps_local)  \n",
    "\n",
    "x_t = torch.from_numpy(x_std)\n",
    "if device.type == \"cuda\":\n",
    "    x_t = x_t.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    assert x_t.shape[1] == n_qubits, f\"Giriş boyutu {x_t.shape[1]} != n_qubits={n_qubits}\"\n",
    "except NameError:\n",
    "    pass  \n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = model(x_t).item()\n",
    "\n",
    "print(f\"Tahmin DV: {y_hat:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb3ef766-8991-4cc2-84bb-f59881e46032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanılan kolonlar: ['DVID', 'CMT', 'EVID']\n",
      "Tahmin DV: 6.524476\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    feature_cols = FEATURES_USED \n",
    "except NameError:\n",
    "    feature_cols = FEATURES      \n",
    "\n",
    "print(\"Kullanılan kolonlar:\", feature_cols)\n",
    "\n",
    "\n",
    "sample = {\n",
    "    \"BW\":   100.0,\n",
    "    \"COMED\":1.0,\n",
    "    \"DOSE\": 1.0,\n",
    "    \"TIME\": 480.0,\n",
    "    \"EVID\": 0.0,\n",
    "    \"MDV\":  0.0,\n",
    "    \"AMT\":  0.0,\n",
    "    \"CMT\":  3.0,\n",
    "    \"DVID\": 2.0,\n",
    "}\n",
    "\n",
    "sample_df = pd.DataFrame([sample], columns=feature_cols).astype(np.float64)\n",
    "\n",
    "eps_local = 1e-8 if 'eps' not in globals() else float(eps)\n",
    "x = sample_df.to_numpy(dtype=np.float64)                           \n",
    "x_std = (x - mean_.astype(np.float64)) / (std_.astype(np.float64) + eps_local)\n",
    "\n",
    "x_t = torch.from_numpy(x_std)\n",
    "if device.type == \"cuda\":\n",
    "    x_t = x_t.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    assert x_t.shape[1] == n_qubits, f\"Giriş boyutu {x_t.shape[1]} != n_qubits={n_qubits}\"\n",
    "except NameError:\n",
    "    pass  \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = model(x_t).item()\n",
    "\n",
    "print(f\"Tahmin DV: {y_hat:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49293a8e-8299-427e-9a68-dac908dab4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vqnn-yenv)",
   "language": "python",
   "name": "vqnn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
